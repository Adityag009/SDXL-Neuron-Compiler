# Fine-tuning SDXL Model Compilation on AWS Neuron

This project demonstrates the process of fine-tuning and compiling an SDXL model using AWS Neuron architecture. The compilation was carried out on an inf2 EC2 instance with the Hugging Face AMI to optimize the model for AWS Neuron's hardware.

The notebook included in this repository provides detailed steps for others looking to compile their own models using a similar setup. It offers valuable insights into configuring, fine-tuning, and optimizing models on AWS infrastructure for improved performance and scalability.

Feel free to explore and adapt the notebook to suit your specific use case.










